{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lnrdmnc/NER-NLP/blob/main/BERT_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OHcfw_esypQ"
      },
      "source": [
        "**Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G7-RsIGws0W5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import  DistilBertForTokenClassification\n",
        "\n",
        "from torch.optim import AdamW\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNKoda08suAq"
      },
      "source": [
        "**Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlC3hsd3sBkA",
        "outputId": "ac2cc7cb-de68-42e0-ce29-3c3954d14ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    20000 non-null  object\n",
            " 1   labels  20000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 312.6+ KB\n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/lnrdmnc/NER-NLP/main/dataset/ner.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Dimensione del campione desiderato\n",
        "sample_size = 20000  # Ad esempio, per ridurre il dataset a 1.000 entry\n",
        "\n",
        "# Estrai un campione casuale senza rimpiazzo\n",
        "df_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "# Salva il dataset ridotto, se necessario\n",
        "df_sample.to_csv('reduced_dataset.csv', index=False)\n",
        "df=pd.read_csv('reduced_dataset.csv')\n",
        "\n",
        "df.head(5)\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEo_Sfl6EhVL",
        "outputId": "b418c462-3fb4-44f5-c68c-c2ae344edb51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      0\n",
              "labels    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "z6jDcPvyEncU",
        "outputId": "196bf653-2685-476c-fc6a-1d4d02f87561"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  \\\n",
              "count                                               20000   \n",
              "unique                                              19923   \n",
              "top     The conflict leaves thousands of people dead e...   \n",
              "freq                                                    5   \n",
              "\n",
              "                             labels  \n",
              "count                         20000  \n",
              "unique                        14724  \n",
              "top     O O O O O O O O O O O O O O  \n",
              "freq                            193  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c543e969-f571-45cc-8d1d-62e94ec5ccef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20000</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>19923</td>\n",
              "      <td>14724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>The conflict leaves thousands of people dead e...</td>\n",
              "      <td>O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c543e969-f571-45cc-8d1d-62e94ec5ccef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c543e969-f571-45cc-8d1d-62e94ec5ccef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c543e969-f571-45cc-8d1d-62e94ec5ccef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c394a220-d1aa-4a8d-af77-c8118b933fa2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c394a220-d1aa-4a8d-af77-c8118b933fa2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c394a220-d1aa-4a8d-af77-c8118b933fa2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          19923,\n          \"5\",\n          \"20000\"\n        ],\n        \"num_unique_values\": 4,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          14724,\n          \"193\",\n          \"20000\"\n        ],\n        \"num_unique_values\": 4,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_valori_colonna = df['labels'].unique\n",
        "print(lista_valori_colonna)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP3QU3IpFF06",
        "outputId": "1489a99e-8fc8-4589-ead2-9f45829f3488"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Series.unique of 0        O O O O B-per I-per O B-org O O B-gpe O O O O ...\n",
            "1        O O O O O O O O O O O O O O O B-org I-org O O ...\n",
            "2        O O O O O O O O B-per I-per O B-gpe B-per I-pe...\n",
            "3        B-per O O O B-geo O O O O O O B-geo O O B-tim ...\n",
            "4        O O O O O O O O O O O O B-geo I-geo O B-geo I-...\n",
            "                               ...                        \n",
            "19995    O O B-gpe O O O O O O O O O O O O O O O O O O ...\n",
            "19996    O O O O O B-gpe O O O O O O O O O O B-geo I-ge...\n",
            "19997    O O O B-tim O O B-geo O O B-geo O O O O O O O ...\n",
            "19998    O O B-geo O O O B-gpe O O O O O O O O O O O O ...\n",
            "19999    O O B-gpe O O B-gpe O O O O O O B-tim I-tim O ...\n",
            "Name: labels, Length: 20000, dtype: object>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVXmhC8ns0r3"
      },
      "source": [
        "**Data Pre Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vkazfZm_s55s",
        "outputId": "fbcc8682-379f-444b-9908-721b3ec3e1af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensione del set di allenamento: 16000\n",
            "Dimensione del set di sviluppo: 2000\n",
            "Dimensione del set di test: 2000\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Rendi tutto minuscolo per uniformità\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Rimuovi spazi multipli\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)  # Rimuovi caratteri speciali (opzionale)\n",
        "    return text\n",
        "\n",
        "\n",
        "N = 1_000\n",
        "#change columns names\n",
        "df.rename(columns = {'text':'sentence', 'labels':'tags'}, inplace = True)\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/lnrdmnc/NER-NLP/main/dataset/ner.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Dimensione del campione desiderato\n",
        "sample_size = 20000\n",
        "df_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "# Salva il dataset ridotto, se necessario\n",
        "df_sample.to_csv('reduced_dataset.csv', index=False)\n",
        "df = pd.read_csv('reduced_dataset.csv')\n",
        "\n",
        "# Pulizia del testo\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Rendi tutto minuscolo per uniformità\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Rimuovi spazi multipli\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)  # Rimuovi caratteri speciali (opzionale)\n",
        "    return text\n",
        "\n",
        "df['sentence'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Cambia i nomi delle colonne\n",
        "df.rename(columns={'sentence': 'sentence', 'labels': 'tags'}, inplace=True)\n",
        "\n",
        "# Divisione del dataset\n",
        "train_size = int(0.8 * len(df))\n",
        "df_train, df_remaining = np.split(df.sample(frac=1, random_state=42), [train_size])\n",
        "\n",
        "dev_test_size = len(df_remaining) // 2\n",
        "df_dev, df_test = np.split(df_remaining, [dev_test_size])\n",
        "\n",
        "# Assicurati che le dimensioni dei set di allenamento, sviluppo e test siano corrette\n",
        "print(\"Dimensione del set di allenamento:\", len(df_train))\n",
        "print(\"Dimensione del set di sviluppo:\", len(df_dev))\n",
        "print(\"Dimensione del set di test:\", len(df_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizzazzione e Vectorizzazione**"
      ],
      "metadata": {
        "id": "ia_UX000DW7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configura i parametri di vectorizzazione\n",
        "vocab_size = 46000\n",
        "sequence_length = 50  # Scegli una lunghezza che si adatti alla maggior parte dei tuoi dati\n",
        "\n",
        "# Crea un layer di vectorizzazione\n",
        "vectorizer = TextVectorization(max_tokens=vocab_size, output_sequence_length=sequence_length, standardize=clean_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ivz74CyTDkAO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkqMXkO6s6VK"
      },
      "source": [
        "**Classe DistilbertNer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X3mdJ2OTtq9V"
      },
      "outputs": [],
      "source": [
        "class DistilbertNER(nn.Module):\n",
        "  \"\"\"\n",
        "  Implement NN class based on distilbert pretrained from Hugging face.\n",
        "  Inputs :\n",
        "    tokens_dim : int specifyng the dimension of the classifier\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, tokens_dim):\n",
        "    super(DistilbertNER,self).__init__()\n",
        "\n",
        "    if type(tokens_dim) != int:\n",
        "            raise TypeError('Please tokens_dim should be an integer')\n",
        "\n",
        "    if tokens_dim <= 0:\n",
        "          raise ValueError('Classification layer dimension should be at least 1')\n",
        "\n",
        "    self.pretrained = DistilBertForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels = tokens_dim) #set the output of each token classifier = unique_lables\n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels = None): #labels are needed in order to compute the loss\n",
        "    \"\"\"\n",
        "  Forwad computation of the network\n",
        "  Input:\n",
        "    - inputs_ids : from model tokenizer\n",
        "    - attention :  mask from model tokenizer\n",
        "    - labels : if given the model is able to return the loss value\n",
        "  \"\"\"\n",
        "\n",
        "    #inference time no labels\n",
        "    if labels == None:\n",
        "      out = self.pretrained(input_ids = input_ids, attention_mask = attention_mask )\n",
        "      return out\n",
        "\n",
        "    out = self.pretrained(input_ids = input_ids, attention_mask = attention_mask , labels = labels)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2MZ08C7tn_3"
      },
      "source": [
        "NerDataset CLass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LPqhz9jftlb8"
      },
      "outputs": [],
      "source": [
        "class NerDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  Custom dataset implementation to get (text,labels) tuples\n",
        "  Inputs:\n",
        "   - df : dataframe with columns [tags, sentence]\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, df):\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "      raise TypeError('Input should be a dataframe')\n",
        "\n",
        "    if \"tags\" not in df.columns or \"sentence\" not in df.columns:\n",
        "      raise ValueError(\"Dataframe should contain 'tags' and 'sentence' columns\")\n",
        "\n",
        "\n",
        "\n",
        "    tags_list = [i.split() for i in df[\"tags\"].values.tolist()]\n",
        "    texts = df[\"sentence\"].values.tolist()\n",
        "\n",
        "    self.texts = [tokenizer(text, padding = \"max_length\", truncation = True, return_tensors = \"pt\") for text in texts]\n",
        "    self.labels = [match_tokens_labels(text, tags) for text,tags in zip(self.texts, tags_list)]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_text = self.texts[idx]\n",
        "    batch_labels = self.labels[idx]\n",
        "\n",
        "    return batch_text, torch.LongTensor(batch_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkgTjPsNtsWU"
      },
      "source": [
        "Metriche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I-FPxcZ4tt0C"
      },
      "outputs": [],
      "source": [
        "class MetricsTracking():\n",
        "  \"\"\"\n",
        "  In order make the train loop lighter I define this class to track all the metrics that we are going to measure for our model.\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "\n",
        "    self.total_acc = 0\n",
        "    self.total_f1 = 0\n",
        "    self.total_precision = 0\n",
        "    self.total_recall = 0\n",
        "\n",
        "  def update(self, predictions, labels , ignore_token = -100):\n",
        "    '''\n",
        "    Call this function every time you need to update your metrics.\n",
        "    Where in the train there was a -100, were additional token that we dont want to label, so remove them.\n",
        "    If we flatten the batch its easier to access the indexed = -100\n",
        "\n",
        "    '''\n",
        "    predictions = predictions.flatten()\n",
        "    labels = labels.flatten()\n",
        "\n",
        "    predictions = predictions[labels != ignore_token]\n",
        "    labels = labels[labels != ignore_token]\n",
        "\n",
        "    predictions = predictions.to(\"cpu\")\n",
        "    labels = labels.to(\"cpu\")\n",
        "\n",
        "    acc = accuracy_score(labels,predictions)\n",
        "    f1 = f1_score(labels, predictions, average = \"macro\")\n",
        "    precision = precision_score(labels, predictions, average = \"macro\")\n",
        "    recall = recall_score(labels, predictions, average = \"macro\")\n",
        "\n",
        "    self.total_acc  += acc\n",
        "    self.total_f1 += f1\n",
        "    self.total_precision += precision\n",
        "    self.total_recall  += recall\n",
        "\n",
        "  def return_avg_metrics(self,data_loader_size):\n",
        "    n = data_loader_size\n",
        "    metrics = {\n",
        "        \"acc\": round(self.total_acc / n ,3),\n",
        "        \"f1\": round(self.total_f1 / n, 3),\n",
        "        \"precision\" : round(self.total_precision / n, 3),\n",
        "        \"recall\": round(self.total_recall / n, 3)\n",
        "          }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQT32H2Yt1-T"
      },
      "source": [
        "**Custom method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mi7iAgrnt2K-"
      },
      "outputs": [],
      "source": [
        "def tags_2_labels(tags : str, tag2idx : dict):\n",
        "  '''\n",
        "  Method that takes a list of tags and a dictionary mapping and returns a list of labels (associated).\n",
        "  Used to create the \"label\" column in df from the \"tags\" column.\n",
        "  '''\n",
        "  return [tag2idx[tag] if tag in tag2idx else unseen_label for tag in tags.split()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWFvPpNn0egy"
      },
      "source": [
        "**tags mapping**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nDqPXfbKt32e"
      },
      "outputs": [],
      "source": [
        "def tags_mapping(tags_series : pd.Series):\n",
        "  \"\"\"\n",
        "  tag_series = df column with tags for each sentence.\n",
        "\n",
        "  Returns:\n",
        "    - dictionary mapping tags to indexes (label)\n",
        "    - dictionary mappign inedexes to tags\n",
        "    - The label corresponding to tag 'O'\n",
        "    - A set of unique tags ecountered in the trainind df, this will define the classifier dimension\n",
        "  \"\"\"\n",
        "\n",
        "  if not isinstance(tags_series, pd.Series):\n",
        "      raise TypeError('Input should be a padas Series')\n",
        "\n",
        "  unique_tags = set()\n",
        "\n",
        "  for tag_list in df_train[\"tags\"]:\n",
        "    for tag in tag_list.split():\n",
        "      unique_tags.add(tag)\n",
        "\n",
        "\n",
        "  tag2idx = {k:v for v,k in enumerate(sorted(unique_tags))}\n",
        "  idx2tag = {k:v for v,k in tag2idx.items()}\n",
        "\n",
        "  unseen_label = tag2idx[\"O\"]\n",
        "\n",
        "  return tag2idx, idx2tag, unseen_label, unique_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6P__CCO09v3"
      },
      "source": [
        "Match token labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5EL6vUyi1Bei"
      },
      "outputs": [],
      "source": [
        "def match_tokens_labels(tokenized_input, tags, ignore_token = -100):\n",
        "        '''\n",
        "        Used in the custom dataset.\n",
        "        -100 will be tha label used to match additional tokens like [CLS] [PAD] that we dont care about.\n",
        "\n",
        "        Inputs :\n",
        "          - tokenized_input : tokenizer over the imput text -> {input_ids, attention_mask}\n",
        "          - tags : is a single label array -> [O O O O O O O O O O O O O O B-tim O]\n",
        "\n",
        "        Returns a list of labels that match the tokenized text -> [-100, 3,5,6,-100,...]\n",
        "        '''\n",
        "\n",
        "        #gives an array [ None , 0 , 1 ,2 ,... None]. Each index tells the word of reference of the token\n",
        "        word_ids = tokenized_input.word_ids()\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "\n",
        "            if word_idx is None:\n",
        "                label_ids.append(ignore_token)\n",
        "\n",
        "            #if its equal to the previous word we can add the same label id of the provious or -100\n",
        "            else :\n",
        "                try:\n",
        "                  reference_tag = tags[word_idx]\n",
        "                  label_ids.append(tag2idx[reference_tag])\n",
        "                except:\n",
        "                  label_ids.append(ignore_token)\n",
        "\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        return label_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-rPTXB2t2gR"
      },
      "source": [
        "Freeze model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4fUEthuo03iU"
      },
      "outputs": [],
      "source": [
        "def freeze_model(model,num_layers = 1):\n",
        "  \"\"\"\n",
        "  Freeze last num_layers of a model to prevent ctastrophic forgetting.\n",
        "  Doesn't seem to work weel, its better to fine tune the entire netwok\n",
        "  \"\"\"\n",
        "  for id , params in enumerate(model.parameters()):\n",
        "    if id == len(list(model.parameters())) - num_layers:\n",
        "      print(\"last layer unfreezed\")\n",
        "      params.requires_grad = True\n",
        "    else:\n",
        "      params.requires_grad = False\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRaocWM01Kwh"
      },
      "source": [
        "Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eaCB31eC1IWF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_loop(model, train_dataset, dev_dataset, optimizer, batch_size, epochs):\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_values = []  # Lista per memorizzare i valori della loss\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        train_metrics = MetricsTracking()\n",
        "        total_loss_train = 0\n",
        "\n",
        "        model.train()  # Modalità di addestramento\n",
        "\n",
        "        for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input_id, mask, train_label)\n",
        "            loss, logits = output.loss, output.logits\n",
        "            predictions = logits.argmax(dim=-1)\n",
        "\n",
        "            train_metrics.update(predictions, train_label)\n",
        "            total_loss_train += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_values.append(total_loss_train / len(train_dataloader))  # Salvataggio della loss\n",
        "\n",
        "        model.eval()  # Modalità di valutazione\n",
        "\n",
        "        dev_metrics = MetricsTracking()\n",
        "        total_loss_dev = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for dev_data, dev_label in dev_dataloader:\n",
        "                dev_label = dev_label.to(device)\n",
        "                mask = dev_data['attention_mask'].squeeze(1).to(device)\n",
        "                input_id = dev_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask, dev_label)\n",
        "                loss, logits = output.loss, output.logits\n",
        "\n",
        "                predictions = logits.argmax(dim=-1)\n",
        "\n",
        "                dev_metrics.update(predictions, dev_label)\n",
        "                total_loss_dev += loss.item()\n",
        "\n",
        "        train_results = train_metrics.return_avg_metrics(len(train_dataloader))\n",
        "        dev_results = dev_metrics.return_avg_metrics(len(dev_dataloader))\n",
        "\n",
        "        print(f\"TRAIN \\nLoss: {total_loss_train / len(train_dataset)} \\nMetrics {train_results}\\n\")\n",
        "        print(f\"VALIDATION \\nLoss {total_loss_dev / len(dev_dataset)} \\nMetrics{dev_results}\\n\")\n",
        "\n",
        "    # Plot della curva di apprendimento\n",
        "    plt.plot(loss_values)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Learning Curve')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mTH8U571Nnu"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRXXo8yc1Rll",
        "outputId": "e3b552f6-4f10-4856-82a8-a5ec47140cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 4000/4000 [11:09<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.09381324873601261 \n",
            "Metrics {'acc': 0.882, 'f1': 0.529, 'precision': 0.571, 'recall': 0.533}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.07792728986032307 \n",
            "Metrics{'acc': 0.901, 'f1': 0.608, 'precision': 0.634, 'recall': 0.623}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 2264/4000 [22:10<04:21,  6.64it/s]"
          ]
        }
      ],
      "source": [
        "#create tag-label mapping\n",
        "tag2idx, idx2tag , unseen_label, unique_tags = tags_mapping(df_train[\"tags\"])\n",
        "\n",
        "#create the label column from tag. Unseen labels will be tagged as \"O\"\n",
        "for df in [df_train, df_dev, df_test]:\n",
        "  df[\"labels\"] = df[\"tags\"].apply(lambda tags : tags_2_labels(tags, tag2idx))\n",
        "  #original text\n",
        "text = df_train[\"sentence\"].values.tolist()\n",
        "\n",
        "#toeknized text\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "text_tokenized = tokenizer(text , padding = \"max_length\" , truncation = True, return_tensors = \"pt\" )\n",
        "\n",
        "#mapping token to original word\n",
        "word_ids = text_tokenized.word_ids()\n",
        "model = DistilbertNER(len(unique_tags))\n",
        "#Prevent Catastrofic Forgetting\n",
        "#model = freeze_model(model, num_layers = 2)\n",
        "\n",
        "#datasets\n",
        "train_dataset = NerDataset(df_train)\n",
        "dev_dataset = NerDataset(df_dev)\n",
        "\n",
        "lr = 1e-2\n",
        "optimizer = SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
        "\n",
        "\n",
        "#MAIN\n",
        "parameters = {\n",
        "    \"model\": model,\n",
        "    \"train_dataset\": train_dataset,\n",
        "    \"dev_dataset\" : dev_dataset,\n",
        "    \"optimizer\" : optimizer,\n",
        "    \"batch_size\" : 4,\n",
        "    \"epochs\" : 10\n",
        "}\n",
        "\n",
        "train_loop(**parameters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installazione  delle dipendenze**"
      ],
      "metadata": {
        "id": "MBO-P-thVK5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[onnx]"
      ],
      "metadata": {
        "id": "Ggd86zDaVLDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvataggio del modello"
      ],
      "metadata": {
        "id": "iVWfVUmZaYvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "# Load tokenizer and TensorFlow weights from the Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "# Save to disk\n",
        "tokenizer.save_pretrained(\"local-tf1-checkpoint\")\n",
        "tf_model.save_pretrained(\"local-tf1-checkpoint\")"
      ],
      "metadata": {
        "id": "D8QHqc5Ab496"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caricamento del modello**"
      ],
      "metadata": {
        "id": "x6SpVCNwm694"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "# Carica il tokenizer salvato\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n",
        "# Carica il modello salvato\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n"
      ],
      "metadata": {
        "id": "C2PgTo4sm5qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "def predict_sentiment(text, model, tokenizer, max_length=128):\n",
        "    encoding = tokenizer(text, return_tensors='tf', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    outputs = model.predict([input_ids, attention_mask])\n",
        "    logits = outputs.logits\n",
        "    predicted_class = tf.math.argmax(logits, axis=1).numpy().item()\n",
        "    return \"positive\" if predicted_class == 1 else \"negative\"\n",
        "\n",
        "# Carica il tokenizer e il modello salvati\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"local-tf1-checkpoint\")\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n",
        "text_list=df_train[\"sentence\"].values.tolist()\n",
        "for text in text_list:\n",
        "    sentiment = predict_sentiment(text, model, tokenizer)\n",
        "    print(f\"Testo: {text}, Sentimento: {sentiment}\")\n",
        "    print(f\"Predicted sentiment: {sentiment}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C8Zxj_RUExja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vediamo come si comporta con i dati di test\n",
        "\n"
      ],
      "metadata": {
        "id": "cOkjorLscZMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForTokenClassification\n",
        "\n",
        "def recognize_entities(text, model, tokenizer, max_length=128):\n",
        "    encoding = tokenizer(text, return_tensors='tf', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    predicted_labels = tf.math.argmax(outputs.logits, axis=-1).numpy()[0]\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    entities = []\n",
        "    current_entity = {\"text\": \"\", \"label\": None}\n",
        "    for token, label_id in zip(tokens, predicted_labels):\n",
        "        label = model.config.id2label[label_id]\n",
        "        if label.startswith('B-'):\n",
        "            if current_entity[\"text\"]:\n",
        "                entities.append(current_entity)\n",
        "            current_entity = {\"text\": token, \"label\": label[2:]}\n",
        "        elif label.startswith('I-'):\n",
        "            if current_entity[\"text\"]:\n",
        "                current_entity[\"text\"] += \" \" + token\n",
        "        else:\n",
        "            if current_entity[\"text\"]:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = {\"text\": \"\", \"label\": None}\n",
        "    if current_entity[\"text\"]:\n",
        "        entities.append(current_entity)\n",
        "    return entities\n",
        "\n",
        "# Carica il tokenizer e il modello salvati\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"local-tf1-checkpoint\")\n",
        "model = TFAutoModelForTokenClassification.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n",
        "\n",
        "# Prendi la lista dei testi dalla colonna \"sentence\"\n",
        "text_list = df_test[\"sentence\"].values.tolist()\n",
        "\n",
        "# Itera su ogni testo e riconosci le entità\n",
        "for text in text_list:\n",
        "    entities = recognize_entities(text, model, tokenizer)\n",
        "    print(f\"Testo: {text}\")\n",
        "    print(\"Entità riconosciute:\")\n",
        "    for entity in entities:\n",
        "        print(f\"- Testo: {entity['text']}, Label: {entity['label']}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "FBc8sR_ecc_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning curve pytorch vedi come fare"
      ],
      "metadata": {
        "id": "CnWxZBX_e_4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "vediamo come si comporta con i dati di train"
      ],
      "metadata": {
        "id": "u7-aYoGidN7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForTokenClassification\n",
        "\n",
        "def recognize_entities(text, model, tokenizer, max_length=128):\n",
        "    encoding = tokenizer(text, return_tensors='tf', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    predicted_labels = tf.math.argmax(outputs.logits, axis=-1).numpy()[0]\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    entities = []\n",
        "    current_entity = {\"text\": \"\", \"label\": None}\n",
        "    for token, label_id in zip(tokens, predicted_labels):\n",
        "        label = model.config.id2label[label_id]\n",
        "        if label.startswith('B-'):\n",
        "            if current_entity[\"text\"]:\n",
        "                entities.append(current_entity)\n",
        "            current_entity = {\"text\": token, \"label\": label[2:]}\n",
        "        elif label.startswith('I-'):\n",
        "            if current_entity[\"text\"]:\n",
        "                current_entity[\"text\"] += \" \" + token\n",
        "        else:\n",
        "            if current_entity[\"text\"]:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = {\"text\": \"\", \"label\": None}\n",
        "    if current_entity[\"text\"]:\n",
        "        entities.append(current_entity)\n",
        "    return entities\n",
        "\n",
        "# Carica il tokenizer e il modello salvati\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"local-tf1-checkpoint\")\n",
        "model = TFAutoModelForTokenClassification.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n",
        "\n",
        "# Prendi la lista dei testi dalla colonna \"sentence\"\n",
        "text_list = df_test[\"sentence\"].values.tolist()\n",
        "\n",
        "# Itera su ogni testo e riconosci le entità\n",
        "for text in text_list:\n",
        "    entities = recognize_entities(text, model, tokenizer)\n",
        "    print(f\"Testo: {text}\")\n",
        "    print(\"Entità riconosciute:\")\n",
        "    for entity in entities:\n",
        "        print(f\"- Testo: {entity['text']}, Label: {entity['label']}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "PqowEkUzax-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "change the logging level"
      ],
      "metadata": {
        "id": "lhzxcl6LbaX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import logging as hf_logging\n",
        "\n",
        "hf_logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "FLoAK8uAD4bb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5OSUSq/55sLLY6gQNd1XH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}