{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lnrdmnc/NER-NLP/blob/main/BERT_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OHcfw_esypQ"
      },
      "source": [
        "**Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7-RsIGws0W5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import  DistilBertForTokenClassification\n",
        "\n",
        "from torch.optim import AdamW\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNKoda08suAq"
      },
      "source": [
        "**Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlC3hsd3sBkA",
        "outputId": "1412cae3-56c1-48ce-d8da-da2389d521d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1000 non-null   object\n",
            " 1   labels  1000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 15.8+ KB\n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/lnrdmnc/NER-NLP/main/dataset/ner.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Dimensione del campione desiderato\n",
        "sample_size = 1000  # Ad esempio, per ridurre il dataset a 1.000 entry\n",
        "\n",
        "# Estrai un campione casuale senza rimpiazzo\n",
        "df_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "# Salva il dataset ridotto, se necessario\n",
        "df_sample.to_csv('reduced_dataset.csv', index=False)\n",
        "df=pd.read_csv('reduced_dataset.csv')\n",
        "\n",
        "df.head(5)\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEo_Sfl6EhVL",
        "outputId": "ec61d16c-22be-4b0c-d7b8-e98ffa115c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      0\n",
              "labels    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "z6jDcPvyEncU",
        "outputId": "b0bac56e-27f6-46cc-85e8-b3d7eadf6d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  \\\n",
              "count                                                1000   \n",
              "unique                                               1000   \n",
              "top     The report calls on President Bush and Congres...   \n",
              "freq                                                    1   \n",
              "\n",
              "                           labels  \n",
              "count                        1000  \n",
              "unique                        872  \n",
              "top     O O O O O O O O O O O O O  \n",
              "freq                           14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-813ced0f-cacf-4c3c-8a41-d5b37b247b89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1000</td>\n",
              "      <td>872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>The report calls on President Bush and Congres...</td>\n",
              "      <td>O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-813ced0f-cacf-4c3c-8a41-d5b37b247b89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-813ced0f-cacf-4c3c-8a41-d5b37b247b89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-813ced0f-cacf-4c3c-8a41-d5b37b247b89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60657409-8273-4c9b-b5ac-0ba08f6ad17d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60657409-8273-4c9b-b5ac-0ba08f6ad17d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60657409-8273-4c9b-b5ac-0ba08f6ad17d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1000\",\n          \"The report calls on President Bush and Congress to urge Chinese officials not to use the global war against terrorism as a pretext to suppress minorities ' rights .\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          872,\n          \"14\",\n          \"1000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_valori_colonna = df['labels'].unique\n",
        "print(lista_valori_colonna)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP3QU3IpFF06",
        "outputId": "6b3d11ce-071a-42d8-b16f-20802667943d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Series.unique of 0      O O O O B-per I-per O B-org O O B-gpe O O O O ...\n",
            "1      O O O O O O O O O O O O O O O B-org I-org O O ...\n",
            "2      O O O O O O O O B-per I-per O B-gpe B-per I-pe...\n",
            "3      B-per O O O B-geo O O O O O O B-geo O O B-tim ...\n",
            "4      O O O O O O O O O O O O B-geo I-geo O B-geo I-...\n",
            "                             ...                        \n",
            "995    O O O O O O O O O O O O O O O O O O O O O O O ...\n",
            "996                  B-geo O O O O O O O O O O B-gpe O O\n",
            "997    B-geo O B-tim O O B-org O O O O O O O O O O B-...\n",
            "998    O O O O O O O O O O O O O O O O O O O O O O O ...\n",
            "999    B-per I-per O O O O O B-tim O B-geo O O O O O ...\n",
            "Name: labels, Length: 1000, dtype: object>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVXmhC8ns0r3"
      },
      "source": [
        "**Data Pre Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkazfZm_s55s"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Rendi tutto minuscolo per uniformità\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Rimuovi spazi multipli\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)  # Rimuovi caratteri speciali (opzionale)\n",
        "    return text\n",
        "\n",
        "\n",
        "N = 1_000\n",
        "#change columns names\n",
        "df.rename(columns = {'text':'sentence', 'labels':'tags'}, inplace = True)\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/lnrdmnc/NER-NLP/main/dataset/ner.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Dimensione del campione desiderato\n",
        "sample_size = 20000\n",
        "df_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "# Salva il dataset ridotto, se necessario\n",
        "df_sample.to_csv('reduced_dataset.csv', index=False)\n",
        "df = pd.read_csv('reduced_dataset.csv')\n",
        "\n",
        "# Pulizia del testo\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Rendi tutto minuscolo per uniformità\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Rimuovi spazi multipli\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)  # Rimuovi caratteri speciali (opzionale)\n",
        "    return text\n",
        "\n",
        "df['sentence'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Cambia i nomi delle colonne\n",
        "df.rename(columns={'sentence': 'sentence', 'labels': 'tags'}, inplace=True)\n",
        "\n",
        "# Divisione del dataset\n",
        "train_size = int(0.8 * len(df))\n",
        "df_train, df_remaining = np.split(df.sample(frac=1, random_state=42), [train_size])\n",
        "\n",
        "dev_test_size = len(df_remaining) // 2\n",
        "df_dev, df_test = np.split(df_remaining, [dev_test_size])\n",
        "\n",
        "# Assicurati che le dimensioni dei set di allenamento, sviluppo e test siano corrette\n",
        "print(\"Dimensione del set di allenamento:\", len(df_train))\n",
        "print(\"Dimensione del set di sviluppo:\", len(df_dev))\n",
        "print(\"Dimensione del set di test:\", len(df_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizzazzione e Vectorizzazione**"
      ],
      "metadata": {
        "id": "ia_UX000DW7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configura i parametri di vectorizzazione\n",
        "vocab_size = 46000\n",
        "sequence_length = 50  # Scegli una lunghezza che si adatti alla maggior parte dei tuoi dati\n",
        "\n",
        "# Crea un layer di vectorizzazione\n",
        "vectorizer = TextVectorization(max_tokens=vocab_size, output_sequence_length=sequence_length, standardize=clean_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ivz74CyTDkAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkqMXkO6s6VK"
      },
      "source": [
        "**Classe DistilbertNer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3mdJ2OTtq9V"
      },
      "outputs": [],
      "source": [
        "class DistilbertNER(nn.Module):\n",
        "  \"\"\"\n",
        "  Implement NN class based on distilbert pretrained from Hugging face.\n",
        "  Inputs :\n",
        "    tokens_dim : int specifyng the dimension of the classifier\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, tokens_dim):\n",
        "    super(DistilbertNER,self).__init__()\n",
        "\n",
        "    if type(tokens_dim) != int:\n",
        "            raise TypeError('Please tokens_dim should be an integer')\n",
        "\n",
        "    if tokens_dim <= 0:\n",
        "          raise ValueError('Classification layer dimension should be at least 1')\n",
        "\n",
        "    self.pretrained = DistilBertForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels = tokens_dim) #set the output of each token classifier = unique_lables\n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels = None): #labels are needed in order to compute the loss\n",
        "    \"\"\"\n",
        "  Forwad computation of the network\n",
        "  Input:\n",
        "    - inputs_ids : from model tokenizer\n",
        "    - attention :  mask from model tokenizer\n",
        "    - labels : if given the model is able to return the loss value\n",
        "  \"\"\"\n",
        "\n",
        "    #inference time no labels\n",
        "    if labels == None:\n",
        "      out = self.pretrained(input_ids = input_ids, attention_mask = attention_mask )\n",
        "      return out\n",
        "\n",
        "    out = self.pretrained(input_ids = input_ids, attention_mask = attention_mask , labels = labels)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2MZ08C7tn_3"
      },
      "source": [
        "NerDataset CLass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPqhz9jftlb8"
      },
      "outputs": [],
      "source": [
        "class NerDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  Custom dataset implementation to get (text,labels) tuples\n",
        "  Inputs:\n",
        "   - df : dataframe with columns [tags, sentence]\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, df):\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "      raise TypeError('Input should be a dataframe')\n",
        "\n",
        "    if \"tags\" not in df.columns or \"sentence\" not in df.columns:\n",
        "      raise ValueError(\"Dataframe should contain 'tags' and 'sentence' columns\")\n",
        "\n",
        "\n",
        "\n",
        "    tags_list = [i.split() for i in df[\"tags\"].values.tolist()]\n",
        "    texts = df[\"sentence\"].values.tolist()\n",
        "\n",
        "    self.texts = [tokenizer(text, padding = \"max_length\", truncation = True, return_tensors = \"pt\") for text in texts]\n",
        "    self.labels = [match_tokens_labels(text, tags) for text,tags in zip(self.texts, tags_list)]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_text = self.texts[idx]\n",
        "    batch_labels = self.labels[idx]\n",
        "\n",
        "    return batch_text, torch.LongTensor(batch_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkgTjPsNtsWU"
      },
      "source": [
        "Metriche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-FPxcZ4tt0C"
      },
      "outputs": [],
      "source": [
        "class MetricsTracking():\n",
        "  \"\"\"\n",
        "  In order make the train loop lighter I define this class to track all the metrics that we are going to measure for our model.\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "\n",
        "    self.total_acc = 0\n",
        "    self.total_f1 = 0\n",
        "    self.total_precision = 0\n",
        "    self.total_recall = 0\n",
        "\n",
        "  def update(self, predictions, labels , ignore_token = -100):\n",
        "    '''\n",
        "    Call this function every time you need to update your metrics.\n",
        "    Where in the train there was a -100, were additional token that we dont want to label, so remove them.\n",
        "    If we flatten the batch its easier to access the indexed = -100\n",
        "\n",
        "    '''\n",
        "    predictions = predictions.flatten()\n",
        "    labels = labels.flatten()\n",
        "\n",
        "    predictions = predictions[labels != ignore_token]\n",
        "    labels = labels[labels != ignore_token]\n",
        "\n",
        "    predictions = predictions.to(\"cpu\")\n",
        "    labels = labels.to(\"cpu\")\n",
        "\n",
        "    acc = accuracy_score(labels,predictions)\n",
        "    f1 = f1_score(labels, predictions, average = \"macro\")\n",
        "    precision = precision_score(labels, predictions, average = \"macro\")\n",
        "    recall = recall_score(labels, predictions, average = \"macro\")\n",
        "\n",
        "    self.total_acc  += acc\n",
        "    self.total_f1 += f1\n",
        "    self.total_precision += precision\n",
        "    self.total_recall  += recall\n",
        "\n",
        "  def return_avg_metrics(self,data_loader_size):\n",
        "    n = data_loader_size\n",
        "    metrics = {\n",
        "        \"acc\": round(self.total_acc / n ,3),\n",
        "        \"f1\": round(self.total_f1 / n, 3),\n",
        "        \"precision\" : round(self.total_precision / n, 3),\n",
        "        \"recall\": round(self.total_recall / n, 3)\n",
        "          }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQT32H2Yt1-T"
      },
      "source": [
        "**Custom method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi7iAgrnt2K-"
      },
      "outputs": [],
      "source": [
        "def tags_2_labels(tags : str, tag2idx : dict):\n",
        "  '''\n",
        "  Method that takes a list of tags and a dictionary mapping and returns a list of labels (associated).\n",
        "  Used to create the \"label\" column in df from the \"tags\" column.\n",
        "  '''\n",
        "  return [tag2idx[tag] if tag in tag2idx else unseen_label for tag in tags.split()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWFvPpNn0egy"
      },
      "source": [
        "**tags mapping**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDqPXfbKt32e"
      },
      "outputs": [],
      "source": [
        "def tags_mapping(tags_series : pd.Series):\n",
        "  \"\"\"\n",
        "  tag_series = df column with tags for each sentence.\n",
        "\n",
        "  Returns:\n",
        "    - dictionary mapping tags to indexes (label)\n",
        "    - dictionary mappign inedexes to tags\n",
        "    - The label corresponding to tag 'O'\n",
        "    - A set of unique tags ecountered in the trainind df, this will define the classifier dimension\n",
        "  \"\"\"\n",
        "\n",
        "  if not isinstance(tags_series, pd.Series):\n",
        "      raise TypeError('Input should be a padas Series')\n",
        "\n",
        "  unique_tags = set()\n",
        "\n",
        "  for tag_list in df_train[\"tags\"]:\n",
        "    for tag in tag_list.split():\n",
        "      unique_tags.add(tag)\n",
        "\n",
        "\n",
        "  tag2idx = {k:v for v,k in enumerate(sorted(unique_tags))}\n",
        "  idx2tag = {k:v for v,k in tag2idx.items()}\n",
        "\n",
        "  unseen_label = tag2idx[\"O\"]\n",
        "\n",
        "  return tag2idx, idx2tag, unseen_label, unique_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6P__CCO09v3"
      },
      "source": [
        "Match token labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EL6vUyi1Bei"
      },
      "outputs": [],
      "source": [
        "def match_tokens_labels(tokenized_input, tags, ignore_token = -100):\n",
        "        '''\n",
        "        Used in the custom dataset.\n",
        "        -100 will be tha label used to match additional tokens like [CLS] [PAD] that we dont care about.\n",
        "\n",
        "        Inputs :\n",
        "          - tokenized_input : tokenizer over the imput text -> {input_ids, attention_mask}\n",
        "          - tags : is a single label array -> [O O O O O O O O O O O O O O B-tim O]\n",
        "\n",
        "        Returns a list of labels that match the tokenized text -> [-100, 3,5,6,-100,...]\n",
        "        '''\n",
        "\n",
        "        #gives an array [ None , 0 , 1 ,2 ,... None]. Each index tells the word of reference of the token\n",
        "        word_ids = tokenized_input.word_ids()\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "\n",
        "            if word_idx is None:\n",
        "                label_ids.append(ignore_token)\n",
        "\n",
        "            #if its equal to the previous word we can add the same label id of the provious or -100\n",
        "            else :\n",
        "                try:\n",
        "                  reference_tag = tags[word_idx]\n",
        "                  label_ids.append(tag2idx[reference_tag])\n",
        "                except:\n",
        "                  label_ids.append(ignore_token)\n",
        "\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        return label_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-rPTXB2t2gR"
      },
      "source": [
        "Freeze model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fUEthuo03iU"
      },
      "outputs": [],
      "source": [
        "def freeze_model(model,num_layers = 1):\n",
        "  \"\"\"\n",
        "  Freeze last num_layers of a model to prevent ctastrophic forgetting.\n",
        "  Doesn't seem to work weel, its better to fine tune the entire netwok\n",
        "  \"\"\"\n",
        "  for id , params in enumerate(model.parameters()):\n",
        "    if id == len(list(model.parameters())) - num_layers:\n",
        "      print(\"last layer unfreezed\")\n",
        "      params.requires_grad = True\n",
        "    else:\n",
        "      params.requires_grad = False\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRaocWM01Kwh"
      },
      "source": [
        "Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaCB31eC1IWF"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, train_dataset, dev_dataset, optimizer,  batch_size, epochs):\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "  dev_dataloader = DataLoader(dev_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = model.to(device)\n",
        "\n",
        "  for epoch in range(epochs) :\n",
        "\n",
        "    train_metrics = MetricsTracking()\n",
        "    total_loss_train = 0\n",
        "\n",
        "    model.train() #train mode\n",
        "\n",
        "    for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "      train_label = train_label.to(device)\n",
        "      '''\n",
        "      squeeze in order to match the sizes. From [batch,1,seq_len] --> [batch,seq_len]\n",
        "      '''\n",
        "      mask = train_data['attention_mask'].squeeze(1).to(device)\n",
        "      input_id = train_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(input_id, mask, train_label)\n",
        "      loss, logits = output.loss, output.logits\n",
        "      predictions = logits.argmax(dim= -1)\n",
        "\n",
        "      #compute metrics\n",
        "      train_metrics.update(predictions, train_label)\n",
        "      total_loss_train += loss.item()\n",
        "\n",
        "      #grad step\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    '''\n",
        "    EVALUATION MODE\n",
        "    '''\n",
        "    model.eval()\n",
        "\n",
        "    dev_metrics = MetricsTracking()\n",
        "    total_loss_dev = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for dev_data, dev_label in dev_dataloader:\n",
        "\n",
        "        dev_label = dev_label.to(device)\n",
        "\n",
        "        mask = dev_data['attention_mask'].squeeze(1).to(device)\n",
        "        input_id = dev_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "        output = model(input_id, mask, dev_label)\n",
        "        loss, logits = output.loss, output.logits\n",
        "\n",
        "        predictions = logits.argmax(dim= -1)\n",
        "\n",
        "        dev_metrics.update(predictions, dev_label)\n",
        "        total_loss_dev += loss.item()\n",
        "\n",
        "    train_results = train_metrics.return_avg_metrics(len(train_dataloader))\n",
        "    dev_results = dev_metrics.return_avg_metrics(len(dev_dataloader))\n",
        "\n",
        "    print(f\"TRAIN \\nLoss: {total_loss_train / len(train_dataset)} \\nMetrics {train_results}\\n\" )\n",
        "    print(f\"VALIDATION \\nLoss {total_loss_dev / len(dev_dataset)} \\nMetrics{dev_results}\\n\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mTH8U571Nnu"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480,
          "referenced_widgets": [
            "116b9e66da5b44b79fe629bf66d423e9",
            "b514457f10cd470e9da74b3733fb7c56",
            "32150f9fd894411bb2878d49aff51d9e",
            "984dac3816c543e58db79ec37fe4fd07",
            "4231db152b294342a4056af3ebf9c33e"
          ]
        },
        "id": "RRXXo8yc1Rll",
        "outputId": "c10aa2be-9539-459b-e43c-3ed1dcc95f80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "116b9e66da5b44b79fe629bf66d423e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b514457f10cd470e9da74b3733fb7c56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32150f9fd894411bb2878d49aff51d9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "984dac3816c543e58db79ec37fe4fd07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4231db152b294342a4056af3ebf9c33e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " 12%|█▏        | 959/8000 [1:06:12<8:06:03,  4.14s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-01acc9df99cc>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m }\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-0e0b9238f63e>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, train_dataset, dev_dataset, optimizer, batch_size, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-9c67b3b17d28>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         outputs = self.distilbert(\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    820\u001b[0m                 \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    823\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    585\u001b[0m                 )\n\u001b[1;32m    586\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    588\u001b[0m                     \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \"\"\"\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# Self-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         sa_output = self.attention(\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#create tag-label mapping\n",
        "tag2idx, idx2tag , unseen_label, unique_tags = tags_mapping(df_train[\"tags\"])\n",
        "\n",
        "#create the label column from tag. Unseen labels will be tagged as \"O\"\n",
        "for df in [df_train, df_dev, df_test]:\n",
        "  df[\"labels\"] = df[\"tags\"].apply(lambda tags : tags_2_labels(tags, tag2idx))\n",
        "  #original text\n",
        "text = df_train[\"sentence\"].values.tolist()\n",
        "\n",
        "#toeknized text\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "text_tokenized = tokenizer(text , padding = \"max_length\" , truncation = True, return_tensors = \"pt\" )\n",
        "\n",
        "#mapping token to original word\n",
        "word_ids = text_tokenized.word_ids()\n",
        "model = DistilbertNER(len(unique_tags))\n",
        "#Prevent Catastrofic Forgetting\n",
        "#model = freeze_model(model, num_layers = 2)\n",
        "\n",
        "#datasets\n",
        "train_dataset = NerDataset(df_train)\n",
        "dev_dataset = NerDataset(df_dev)\n",
        "\n",
        "lr = 1e-2\n",
        "optimizer = SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
        "\n",
        "\n",
        "#MAIN\n",
        "parameters = {\n",
        "    \"model\": model,\n",
        "    \"train_dataset\": train_dataset,\n",
        "    \"dev_dataset\" : dev_dataset,\n",
        "    \"optimizer\" : optimizer,\n",
        "    \"batch_size\" : 2,\n",
        "    \"epochs\" : 10\n",
        "}\n",
        "\n",
        "train_loop(**parameters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installazione  delle dipendenze**"
      ],
      "metadata": {
        "id": "MBO-P-thVK5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[onnx]"
      ],
      "metadata": {
        "id": "Ggd86zDaVLDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvataggio del modello"
      ],
      "metadata": {
        "id": "iVWfVUmZaYvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "# Load tokenizer and TensorFlow weights from the Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "# Save to disk\n",
        "tokenizer.save_pretrained(\"local-tf1-checkpoint\")\n",
        "tf_model.save_pretrained(\"local-tf1-checkpoint\")"
      ],
      "metadata": {
        "id": "D8QHqc5Ab496"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caricamento del modello**"
      ],
      "metadata": {
        "id": "x6SpVCNwm694"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "# Carica il tokenizer salvato\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n",
        "# Carica il modello salvato\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n"
      ],
      "metadata": {
        "id": "C2PgTo4sm5qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "change the logging level"
      ],
      "metadata": {
        "id": "lhzxcl6LbaX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import logging as hf_logging\n",
        "\n",
        "hf_logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "FLoAK8uAD4bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "def predict_sentiment(text, model, tokenizer, max_length=128):\n",
        "    encoding = tokenizer(text, return_tensors='tf', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    outputs = model.predict([input_ids, attention_mask])\n",
        "    logits = outputs.logits\n",
        "    predicted_class = tf.math.argmax(logits, axis=1).numpy().item()\n",
        "    return \"positive\" if predicted_class == 1 else \"negative\"\n",
        "\n",
        "# Carica il tokenizer e il modello salvati\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"local-tf1-checkpoint\")\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n",
        "text_list=df_train[\"sentence\"].values.tolist()\n",
        "for text in text_list:\n",
        "    sentiment = predict_sentiment(text, model, tokenizer)\n",
        "    print(f\"Testo: {text}, Sentimento: {sentiment}\")\n",
        "    print(f\"Predicted sentiment: {sentiment}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C8Zxj_RUExja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vediamo come si comporta con i dati di train"
      ],
      "metadata": {
        "id": "u7-aYoGidN7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForTokenClassification\n",
        "\n",
        "def recognize_entities(text, model, tokenizer, max_length=128):\n",
        "    encoding = tokenizer(text, return_tensors='tf', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    outputs = model.predict([input_ids, attention_mask])\n",
        "    predicted_labels = tf.math.argmax(outputs.logits, axis=-1).numpy()[0]\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    entities = []\n",
        "    current_entity = {\"text\": \"\", \"label\": None}\n",
        "    for token, label_id in zip(tokens, predicted_labels):\n",
        "        label = model.config.id2label[label_id]\n",
        "        if label.startswith('B-'):\n",
        "            if current_entity[\"text\"]:\n",
        "                entities.append(current_entity)\n",
        "            current_entity = {\"text\": token, \"label\": label[2:]}\n",
        "        elif label.startswith('I-'):\n",
        "            if current_entity[\"text\"]:\n",
        "                current_entity[\"text\"] += \" \" + token\n",
        "        else:\n",
        "            if current_entity[\"text\"]:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = {\"text\": \"\", \"label\": None}\n",
        "    if current_entity[\"text\"]:\n",
        "        entities.append(current_entity)\n",
        "    return entities\n",
        "\n",
        "# Carica il tokenizer e il modello salvati\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"local-tf1-checkpoint\")\n",
        "model = TFAutoModelForTokenClassification.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n",
        "\n",
        "# Prendi la lista dei testi dalla colonna \"sentence\"\n",
        "text_list = df_train[\"sentence\"].values.tolist()\n",
        "\n",
        "# Itera su ogni testo e riconosci le entità\n",
        "for text in text_list:\n",
        "    entities = recognize_entities(text, model, tokenizer)\n",
        "    print(f\"Testo: {text}\")\n",
        "    print(\"Entità riconosciute:\")\n",
        "    for entity in entities:\n",
        "        print(f\"- Testo: {entity['text']}, Label: {entity['label']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "PqowEkUzax-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vediamo come si comporta con i dati di test\n",
        "\n"
      ],
      "metadata": {
        "id": "cOkjorLscZMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForTokenClassification\n",
        "\n",
        "def recognize_entities(text, model, tokenizer, max_length=128):\n",
        "    encoding = tokenizer(text, return_tensors='tf', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    outputs = model.predict([input_ids, attention_mask])\n",
        "    predicted_labels = tf.math.argmax(outputs.logits, axis=-1).numpy()[0]\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    entities = []\n",
        "    current_entity = {\"text\": \"\", \"label\": None}\n",
        "    for token, label_id in zip(tokens, predicted_labels):\n",
        "        label = model.config.id2label[label_id]\n",
        "        if label.startswith('B-'):\n",
        "            if current_entity[\"text\"]:\n",
        "                entities.append(current_entity)\n",
        "            current_entity = {\"text\": token, \"label\": label[2:]}\n",
        "        elif label.startswith('I-'):\n",
        "            if current_entity[\"text\"]:\n",
        "                current_entity[\"text\"] += \" \" + token\n",
        "        else:\n",
        "            if current_entity[\"text\"]:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = {\"text\": \"\", \"label\": None}\n",
        "    if current_entity[\"text\"]:\n",
        "        entities.append(current_entity)\n",
        "    return entities\n",
        "\n",
        "# Carica il tokenizer e il modello salvati\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"local-tf1-checkpoint\")\n",
        "model = TFAutoModelForTokenClassification.from_pretrained(\"local-tf1-checkpoint\")\n",
        "\n",
        "\n",
        "# Prendi la lista dei testi dalla colonna \"sentence\"\n",
        "text_list = df_test[\"sentence\"].values.tolist()\n",
        "\n",
        "# Itera su ogni testo e riconosci le entità\n",
        "for text in text_list:\n",
        "    entities = recognize_entities(text, model, tokenizer)\n",
        "    print(f\"Testo: {text}\")\n",
        "    print(\"Entità riconosciute:\")\n",
        "    for entity in entities:\n",
        "        print(f\"- Testo: {entity['text']}, Label: {entity['label']}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBc8sR_ecc_0",
        "outputId": "69eb5a59-5ec0-48ad-e916-bf6078df2142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "Testo: World famous Russian cellist and conductor , Mstislav Rostropovich , who appeared frail at his 80th birthday celebration last month , has been hospitalized in Moscow for the second time this year .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "Testo: The accident happened in Bhandara district , some 925 kilometers northeast of the state capital , Mumbai .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "Testo: Somalia 's transitional government has ordered the closure of four major news outlets in the capital , Mogadishu .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "Testo: An Ant , going to a river to drink , fell in , and was carried along in the stream .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "Testo: Millions of striking workers brought parts of India to a standstill Tuesday as they protested price hikes and alleged anti-labor policies .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "Testo: Jurors in the Phil Spector murder trial were on June 5 shown a handgun found at the feet of an actress slain in the music producer 's mansion .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "Testo: This is the latest of more than 40 suspected U.S. missile strikes on militant targets in northwest Pakistan over the past year .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 313ms/step\n",
            "Testo: Safina ousted Anabel Medina Garrigues of Spain in straight sets ( 06-Jan , 06-Mar ) .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 279ms/step\n",
            "Testo: A military statement says one of the suspects was the \" number one high value \" target of the U.S. brigade that captured him .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 310ms/step\n",
            "Testo: It was the first electoral defeat for Mr. Chavez in nine years .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 224ms/step\n",
            "Testo: The document replaces a controversial memo issued in August , 2002 , which defined torture in such a way that critics said only the most severe types of interrogation techniques would not be permissible .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "Testo: Indonesia plans to boost public awareness of the disease and restructure its poultry industry to reach its goal .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "Testo: Billionaire investor says the U.S. economy could fall into recession in 2007 .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 220ms/step\n",
            "Testo: Mr. Rangel said Tuesday Venezuela is buying the rifles to strengthen its national defense , and that the purchase should not concern Washington .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "Testo: Every night , the maintenance man would remove them and the next day , The girls would put them back .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 174ms/step\n",
            "Testo: The construction on the Baku-T'bilisi-Ceyhan oil pipeline , the Baku-T'bilisi-Erzerum gas pipeline , and the Kars-Akhalkalaki Railroad are part of a strategy to capitalize on Georgia 's strategic location between Europe and Asia and develop its role as a transit point for gas , oil and other goods .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "Testo: They said the training is part of the mandate of the African Union peacekeeping mission in Somalia .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "Testo: Pakistan 's military said most of the attackers came from the Afghan side of the border , and were joined by local Taliban fighters in the northwestern Mohmand tribal area , a center of Taliban and al-Qaida activity .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "Testo: In a statement released Saturday , the ayatollah called the failure of Iraqi security forces to decrease the violence plaguing the country \" serious . \"\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "Testo: Separately , Austria Wednesday said an aircraft suspected of transporting CIA terrorist captives flew though its airspace in 2003 .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 212ms/step\n",
            "Testo: \" You ugly brute ! \" he cried ; \" how dare you look at me in that insolent way . \"\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 177ms/step\n",
            "Testo: A shoving match between the Chilean and U.S. agents occurred Saturday when the Chileans tried to stop the Secret Service bodyguards from accompanying the president to a dinner with world leaders .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "Testo: The election could redefine Taiwan 's troubled relationship with mainland China .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "Testo: The agency that monitors daily images of the Arctic ice pack reports the ice in early September reached its minimum but did not retreat as much this year as last .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 220ms/step\n",
            "Testo: The governor of North Carolina has declared a state of emergency and ordered tourists to leave an island in the state 's Outer Banks chain .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 242ms/step\n",
            "Testo: Mr. Weah has alleged there was cheating , including pre-marked ballots , in last week 's second round election pitting him against former Finance Minister Ellen Johnson-Sirleaf .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 226ms/step\n",
            "Testo: Mr. Putin 's letter saluted Mr. Kononov 's contribution to the defeat of the Nazis in World War II , noting that 2005 will mark the 60th anniversary of the end of the war .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "Testo: Turkey has stepped up military operations this year against PKK rebels , both inside Turkey and in northern Iraq .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 236ms/step\n",
            "Testo: Iraq 's main Sunni Arab coalition has challenged partial vote results showing a strong lead for a Shi'ite coalition in last week 's parliamentary elections .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 226ms/step\n",
            "Testo: Muslims throughout the region are boycotting Danish goods .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 221ms/step\n",
            "Testo: A Spanish judge , Fernando Andreu , ordered the Somali men released on Friday .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 242ms/step\n",
            "Testo: The presidents of South Africa and Nigeria have arrived in Ivory Coast in another effort to resolve a standoff over the selection of a new prime minister .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 226ms/step\n",
            "Testo: North Korea has called Vice President Dick Cheney a \" bloodthirsty beast \" and said his comments describing ruler Kim Jong-il as \" irresponsible \" could keep Pyongyang away from future nuclear negotiations .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "Testo: Last year , fires destroyed more than 2,00,000 hectares and some 2,000 homes in southern California .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 215ms/step\n",
            "Testo: Carlsen will face another Thai opponent , 43rd-ranked Paradorn Srichaphan , in the second round .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 224ms/step\n",
            "Testo: In 1935 the Philippines became a self-governing commonwealth .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "Testo: A spokesman for the International Security Assistance Force says NATO and Afghan forces have killed about 50 Taleban insurgents in an operation in southern Afghanistan .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 221ms/step\n",
            "Testo: Dozens of unconscious women and children were sent to nearby hospitals .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 219ms/step\n",
            "Testo: In a statement Wednesday , FIFA said it fined the Mexican Federation more than $ 5,83,000 after Aaron Galindo and Salvador Carmona tested positive for the steroid nandrolone .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "Testo: Blagojevic appealed the conviction .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 279ms/step\n",
            "Testo: The war games are being held near nuclear facilities .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 341ms/step\n",
            "Testo: I am not a believer in sances , but I went to one just to see what they are like .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 285ms/step\n",
            "Testo: A senior Burmese prison official says more than 9,000 inmates promised freedom under the military government 's prisoner release program will be freed by the end of Friday .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 334ms/step\n",
            "Testo: The French News Agency quotes Barman as saying people get arrested in Yemen based on \" wrong U.S. intelligence information . \"\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 224ms/step\n",
            "Testo: A statement from Pakistan 's foreign ministry says Qureshi hopes what it called a \" military surge \" in Afghanistan will be paired with a politically and developmentaly-oriented surge .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 222ms/step\n",
            "Testo: The U.N. chief says it is important to work quickly to reform the global financial system .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 237ms/step\n",
            "Testo: Israeli forces have been carrying out brief incursions into Gaza since launching an offensive in late June to stop cross-border rocket attacks and rescue a captured Israeli soldier .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "Testo: It says the delegates will discuss how to ease the burden of countries hosting large numbers of Iraqi refugees .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 167ms/step\n",
            "Testo: He said he thinks a determination will come after the two men consult about the timing of such a move , so that , in his words , it does not create unnecessary problems .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "Testo: Various rebel groups are fighting for independence from New Delhi 's control or a merger with Pakistan .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "Testo: Nearly all of the Palestinian refugees living in the camp have fled .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "Testo: United Nations Secretary-General Kofi Annan says he is deeply disappointed in the decision of Burma 's military rulers to extend the house arrest of opposition leader Aung San Suu Kyi for another six months .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "Testo: The tape - first broadcast Thursday by Arab broadcaster Al-Jazeera - says there are plans for a new attack in the United States , but offers a \" long-term \" truce if American forces pull out of Iraq and Afghanistan .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "Testo: Kazakhstan , geographically the largest of the former Soviet republics , excluding Russia , possesses enormous fossil fuel reserves and plentiful supplies of other minerals and metals , such as uranium , copper , and zinc .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "Testo: The AU summit has so far focused largely on the political crisis in Zimbabwe .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "Testo: This week in Washington , former senator and astronaut John Glenn joined members of the U.S. Congress , officials from NASA and others for a sneak preview .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 167ms/step\n",
            "Testo: Officials in India say a blast on a packed train that killed at least 12 people and left dozens wounded was apparently caused by a bomb .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "Testo: Authorities are destroying hundreds of thousands of birds and have quarantined a number of people who have symptoms of the disease .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 167ms/step\n",
            "Testo: British police have been out in force in Edinburgh , Scotland , Monday , where demonstrators have begun protesting the G-Eight conference of industrialized nations that opens Wednesday .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "Testo: They said an explosive device probably caused the blast , but said authorities are still investigating .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 166ms/step\n",
            "Testo: But South Carolina Republican Lindsay Graham dismissed Democratic party opposition , saying they are merely playing politics with the nomination .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "Testo: World health officials have long feared the virus might change into a form easily transferable among people , triggering a deadly global pandemic .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "Testo: The huge explosion killed 22 people , including the top U.N. envoy in Iraq , Sergio Vieira de Mello , and injured hundreds of others .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 174ms/step\n",
            "Testo: New anti-smoking laws also took effect New Year 's Day in Belgium .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 165ms/step\n",
            "Testo: Typhoon Damrey , now a tropical storm , pounded northern and eastern Vietnam Tuesday , killing at least one person , injuring several others and causing widespread damage .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "Testo: Most of the victims have been in Asia .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "Testo: Police in Istanbul have arrested 63 people taking part in a demonstration ahead of International Women 's Day .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 165ms/step\n",
            "Testo: The report says the proposal seeks a pledge by Iran to end any uranium conversion and enrichment activities .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "Testo: And at least six coalition soldiers were hurt in other attacks in northern Iraq .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "Testo: The idea of a united Africa was conceived four decades ago by Ghana 's first president , Kwame Nkrumah .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "Testo: Military officials say helicopters fired missiles at two offices Friday of the Al-Aqsa Martyrs Brigades in Gaza City .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 167ms/step\n",
            "Testo: The U.S. Defense Department , in a statement Monday , said the article is \" so riddled with errors of fundamental fact \" that it has no credibility .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "Testo: Presidents of member nations Argentina , Brazil , Paraguay and Uruguay are to sign a document Tuesday extending voting rights and lower tariffs to Venezuela .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "Testo: Reports say a final vote on the controversial measure is expected later this week .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "Testo: A European Space Agency probe has completed a three-year mission to test deep space technologies by making a controlled crash on the moon .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 174ms/step\n",
            "Testo: The pontiff also repeated his concern that too few Catholics are giving due reverence to the Eucharist or properly marking Sunday as the Lord 's Day .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "Testo: The hotel is believed to be owned by prominent politician , Bayaman Erkinbayev , who survived an attempt on his life by unknown assailants six weeks ago .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "Testo: Mayor Nagin has vowed to resurrect the city , some 80 percent of which was flooded after Katrina .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "Testo: The unions , which represent some 1.2 million workers , issued the threat on Thursday after rejecting the government 's latest wage offer .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "Testo: Police in Denmark have arrested four Danish Muslims suspected of plotting a terror attack in Europe .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 166ms/step\n",
            "Testo: A lawyer for former Care International worker Margaret Hassan told the French news agency that Ali Lutfi Jassar al-Rawi did not appear at a Thursday appeal hearing .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 220ms/step\n",
            "Testo: Insurgents have killed at least 11 people in attacks across Iraq .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "Testo: Many of the militants operating in the border areas are al-Qaida-linked fighters who fled Afghanistan after U.S.-led forces ousted the Taleban .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "Testo: Rescuers , including Buddhist monks , are struggling to reach survivors before they succumb to disease and starvation .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "Testo: Cross-border raids and incidents have continued despite mediation efforts by Libyan leader Moammar Gadhafi .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 177ms/step\n",
            "Testo: Environmentalists , who have long condemned the project , say the dam 's reservoir will likely become heavily polluted with industrial waste .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "Testo: Aid agencies say five million of Malawi 's 12 million people are in need of food aid .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "Testo: Olmert denies the charges .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "Testo: Abdul Aziz al-Hakim , whose United Iraqi Alliance is expected to dominate the vote , survived the Baghdad attack .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "Testo: Pakistani President Pervez Musharraf first moved to curb the media when he declared a state of emergency on November 3 .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "Testo: A massive 7.9 quake hit Sichuan province in 2008 , killing close to 90,000 people .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "Testo: At least 20 people have been killed in two attacks in Baghdad .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "Testo: The Dalai Lama signed up for his online account Monday , a day after meeting Twitter founder Evan Williams in Los Angeles , California .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 174ms/step\n",
            "Testo: Currently , Korean exports dominate the exchange , valued at approximately $ 5.4 billion annually .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "Testo: Germany is one of several nations with ships patrolling the pirate-infested waters off Somalia .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "Testo: Some members of Somalia 's new government have rejected plans for an African peacekeeping force that includes troops from nations bordering Somalia .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "Testo: Indonesian health officials say local tests have confirmed a man has tested positive for the H5N1 strain of bird flu virus .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "Testo: In a separate incident today , authorities said at least two Iraqi soldiers were killed and two others wounded when a roadside bomb struck their patrol near the Iranian border in Diyala province .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "Testo: The U.S. State Department has condemned the bombings in Beirut , saying authorities must arrest those responsible .\n",
            "Entità riconosciute:\n",
            "\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "Testo: It is not clear who planted the bomb .\n",
            "Entità riconosciute:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning curve pytorch vedi come fare"
      ],
      "metadata": {
        "id": "CnWxZBX_e_4n"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAg84OaRYcwFn2ErVWP9kC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}